{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importamos Dataset de kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/saurabhbagchi/books-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24.6M/24.6M [00:06<00:00, 3.75MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/vscode/.cache/kagglehub/datasets/saurabhbagchi/books-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Sample Python code for dataset download\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"saurabhbagchi/books-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset directory: ['books_data']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset_path = \"/home/vscode/.cache/kagglehub/datasets/saurabhbagchi/books-dataset/versions/1\"\n",
    "\n",
    "# List files in the dataset directory\n",
    "files = os.listdir(dataset_path)\n",
    "print(\"Files in dataset directory:\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos los csv de interes: \n",
    "1. books.csv\n",
    "2. ratings.csv\n",
    "3. users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in books_data directory: ['books.csv', 'users.csv', 'ratings.csv']\n",
      "Data files found: ['books.csv', 'users.csv', 'ratings.csv']\n",
      "\n",
      "Loading file: books.csv\n",
      "UTF-8 decoding failed or parsing issue, trying ISO-8859-1 encoding...\n",
      "\n",
      "First 5 rows of books.csv:\n",
      "         ISBN                                         Book-Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            Book-Author  Year-Of-Publication                   Publisher  \\\n",
      "0    Mark P. O. Morford                 2002     Oxford University Press   \n",
      "1  Richard Bruce Wright                 2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este                 1991             HarperPerennial   \n",
      "3      Gina Bari Kolata                 1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                 1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                         Image-URL-S  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "\n",
      "books.csv Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270491 entries, 0 to 270490\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 270491 non-null  object\n",
      " 1   Book-Title           270491 non-null  object\n",
      " 2   Book-Author          270489 non-null  object\n",
      " 3   Year-Of-Publication  270491 non-null  int64 \n",
      " 4   Publisher            270489 non-null  object\n",
      " 5   Image-URL-S          270491 non-null  object\n",
      " 6   Image-URL-M          270491 non-null  object\n",
      " 7   Image-URL-L          270491 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 16.5+ MB\n",
      "None\n",
      "\n",
      "Descriptive Statistics for books.csv:\n",
      "       Year-Of-Publication\n",
      "count        270491.000000\n",
      "mean           1959.704914\n",
      "std             258.207234\n",
      "min               0.000000\n",
      "25%            1989.000000\n",
      "50%            1995.000000\n",
      "75%            2000.000000\n",
      "max            2050.000000\n",
      "\n",
      "Loading file: users.csv\n",
      "UTF-8 decoding failed or parsing issue, trying ISO-8859-1 encoding...\n",
      "\n",
      "First 5 rows of users.csv:\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "\n",
      "users.csv Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278177 entries, 0 to 278176\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   User-ID   278177 non-null  int64  \n",
      " 1   Location  278177 non-null  object \n",
      " 2   Age       167669 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n",
      "None\n",
      "\n",
      "Descriptive Statistics for users.csv:\n",
      "             User-ID            Age\n",
      "count  278177.000000  167669.000000\n",
      "mean   139421.240045      34.751797\n",
      "std     80495.783896      14.430984\n",
      "min         1.000000       0.000000\n",
      "25%     69696.000000      24.000000\n",
      "50%    139419.000000      32.000000\n",
      "75%    209134.000000      44.000000\n",
      "max    278858.000000     244.000000\n",
      "\n",
      "Loading file: ratings.csv\n",
      "UTF-8 decoding failed or parsing issue, trying ISO-8859-1 encoding...\n",
      "\n",
      "First 5 rows of ratings.csv:\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n",
      "\n",
      "ratings.csv Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149766 entries, 0 to 1149765\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149766 non-null  int64 \n",
      " 1   ISBN         1149766 non-null  object\n",
      " 2   Book-Rating  1149766 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n",
      "None\n",
      "\n",
      "Descriptive Statistics for ratings.csv:\n",
      "            User-ID   Book-Rating\n",
      "count  1.149766e+06  1.149766e+06\n",
      "mean   1.403862e+05  2.866906e+00\n",
      "std    8.056191e+04  3.854172e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"/home/vscode/.cache/kagglehub/datasets/saurabhbagchi/books-dataset/versions/1/books_data\"\n",
    "\n",
    "# List files inside books_data\n",
    "files = os.listdir(dataset_path)\n",
    "print(\"Files in books_data directory:\", files)\n",
    "\n",
    "# Filter for CSV or JSON files\n",
    "data_files = [f for f in files if f.endswith(('.csv', '.json'))]\n",
    "print(\"Data files found:\", data_files)\n",
    "\n",
    "# Load and display data\n",
    "if data_files:\n",
    "    for file_name in data_files:\n",
    "        data_path = os.path.join(dataset_path, file_name)  # Iterate over all files\n",
    "        print(f\"\\nLoading file: {file_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Load CSV with proper delimiter and quoting\n",
    "            if data_path.endswith('.csv'):\n",
    "                try:\n",
    "                    df = pd.read_csv(\n",
    "                        data_path, \n",
    "                        encoding='utf-8', \n",
    "                        sep=';',                # Use semicolon as delimiter\n",
    "                        quotechar='\"',          # Handle quoted fields\n",
    "                        on_bad_lines='skip',    # Skip bad lines\n",
    "                        engine='python'         # More robust parsing\n",
    "                    )\n",
    "                except (UnicodeDecodeError, pd.errors.ParserError):\n",
    "                    print(\"UTF-8 decoding failed or parsing issue, trying ISO-8859-1 encoding...\")\n",
    "                    df = pd.read_csv(\n",
    "                        data_path, \n",
    "                        encoding='ISO-8859-1', \n",
    "                        sep=';', \n",
    "                        quotechar='\"',\n",
    "                        on_bad_lines='skip', \n",
    "                        engine='python'\n",
    "                    )\n",
    "\n",
    "            # Load JSON\n",
    "            elif data_path.endswith('.json'):\n",
    "                df = pd.read_json(data_path)\n",
    "            \n",
    "            # Display dataset details\n",
    "            print(f\"\\nFirst 5 rows of {file_name}:\")\n",
    "            print(df.head())\n",
    "\n",
    "            print(f\"\\n{file_name} Info:\")\n",
    "            print(df.info())\n",
    "\n",
    "            print(f\"\\nDescriptive Statistics for {file_name}:\")\n",
    "            print(df.describe())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_name}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"No CSV or JSON data files found in books_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de `dataframes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/vscode/.cache/kagglehub/datasets/saurabhbagchi/books-dataset/versions/1/books_data\"\n",
    "\n",
    "books_path = os.path.join(dataset_path, \"books.csv\")\n",
    "users_path = os.path.join(dataset_path, \"users.csv\")\n",
    "ratings_path = os.path.join(dataset_path, \"ratings.csv\")\n",
    "\n",
    "books_df = pd.read_csv(books_path, sep=';', quotechar='\"', encoding='ISO-8859-1', on_bad_lines='skip', engine='python')\n",
    "users_df = pd.read_csv(users_path, sep=';', quotechar='\"', encoding='ISO-8859-1', on_bad_lines='skip', engine='python')\n",
    "ratings_df = pd.read_csv(ratings_path, sep=';', quotechar='\"', encoding='ISO-8859-1', on_bad_lines='skip', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploracion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗂️ Exploring Books dataset:\n",
      "----------------------------------------\n",
      "Shape: (270491, 8)\n",
      "\n",
      "Columns and Data Types:\n",
      "ISBN                   object\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication     int64\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values per Column:\n",
      "ISBN                   270491\n",
      "Book-Title             241282\n",
      "Book-Author            101696\n",
      "Year-Of-Publication       116\n",
      "Publisher               16727\n",
      "Image-URL-S            270175\n",
      "Image-URL-M            270175\n",
      "Image-URL-L            270175\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "🗂️ Exploring Users dataset:\n",
      "----------------------------------------\n",
      "Shape: (278177, 3)\n",
      "\n",
      "Columns and Data Types:\n",
      "User-ID       int64\n",
      "Location     object\n",
      "Age         float64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110508\n",
      "dtype: int64\n",
      "\n",
      "Unique Values per Column:\n",
      "User-ID     278177\n",
      "Location     56882\n",
      "Age            165\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "🗂️ Exploring Ratings dataset:\n",
      "----------------------------------------\n",
      "Shape: (1149766, 3)\n",
      "\n",
      "Columns and Data Types:\n",
      "User-ID         int64\n",
      "ISBN           object\n",
      "Book-Rating     int64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values per Column:\n",
      "User-ID        105274\n",
      "ISBN           340545\n",
      "Book-Rating        11\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Explore missing values and data types\n",
    "\n",
    "def explore_dataframe(df, name):\n",
    "    print(f\"\\n🗂️ Exploring {name} dataset:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nColumns and Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nUnique Values per Column:\")\n",
    "    print(df.nunique())\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Explore each dataset\n",
    "explore_dataframe(books_df, \"Books\")\n",
    "explore_dataframe(users_df, \"Users\")\n",
    "explore_dataframe(ratings_df, \"Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.149766e+06\n",
       "mean     2.866906e+00\n",
       "std      3.854172e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      7.000000e+00\n",
       "max      1.000000e+01\n",
       "Name: Book-Rating, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df[\"Book-Rating\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
